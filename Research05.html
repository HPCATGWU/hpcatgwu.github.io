<!DOCTYPE html>
<html  >
<head>
  
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1">
  <link rel="shortcut icon" href="assets/images/screen-shot-2018-12-31-at-12.35.34-128x125.png" type="image/x-icon">
  <meta name="description" content="Website Maker Description">
  
  
  <title>Research05</title>
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons/mobirise-icons.css">
  <link rel="stylesheet" href="assets/web/assets/mobirise-icons-bold/mobirise-icons-bold.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-grid.min.css">
  <link rel="stylesheet" href="assets/bootstrap/css/bootstrap-reboot.min.css">
  <link rel="stylesheet" href="assets/tether/tether.min.css">
  <link rel="stylesheet" href="assets/animatecss/animate.min.css">
  <link rel="stylesheet" href="assets/dropdown/css/style.css">
  <link rel="stylesheet" href="assets/socicon/css/styles.css">
  <link rel="stylesheet" href="assets/theme/css/style.css">
  <link rel="preload" href="https://fonts.googleapis.com/css?family=Rubik:300,400,500,600,700,800,900,300i,400i,500i,600i,700i,800i,900i&display=swap" as="style" onload="this.onload=null;this.rel='stylesheet'">
  <noscript><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Rubik:300,400,500,600,700,800,900,300i,400i,500i,600i,700i,800i,900i&display=swap"></noscript>
  <link rel="preload" as="style" href="assets/mobirise/css/mbr-additional.css"><link rel="stylesheet" href="assets/mobirise/css/mbr-additional.css" type="text/css">
  
  
  
  
</head>
<body>
  
  <section class="menu cid-rcO6d1x3lh" once="menu" id="menu1-3v">

    

    <nav class="navbar navbar-expand beta-menu navbar-dropdown align-items-center navbar-fixed-top navbar-toggleable-sm">
        <button class="navbar-toggler navbar-toggler-right" type="button" data-toggle="collapse" data-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
            <div class="hamburger">
                <span></span>
                <span></span>
                <span></span>
                <span></span>
            </div>
        </button>
        <div class="menu-logo">
            <div class="navbar-brand">
                <span class="navbar-logo">
                    <a href="Index.html">
                         <img src="assets/images/screen-shot-2018-12-31-at-12.35.34-122x119.png" alt="" title="" style="height: 2.9rem;">
                    </a>
                </span>
                <span class="navbar-caption-wrap"><a class="navbar-caption text-black display-2" href="index.html#header1-3">HPCAT<br></a></span>
            </div>
        </div>
        <div class="collapse navbar-collapse" id="navbarSupportedContent">
            <ul class="navbar-nav nav-dropdown nav-right" data-app-modern-menu="true"><li class="nav-item">
                    <a class="nav-link link text-black display-4" href="index.html"><span class="mbrib-home mbr-iconfont mbr-iconfont-btn" style="color: rgb(0, 0, 0);"></span>
                        <font size="+1">Home</font></a>
                </li>
                <li class="nav-item">
                    <a class="nav-link link text-black display-4" href="Director.html"><span class="mbrib-user mbr-iconfont mbr-iconfont-btn" style="color: rgb(0, 0, 0);"></span>
                        <font size="+1">Director</font></a>
                </li><li class="nav-item"><a class="nav-link link text-black display-4" href="index.html#content9-23"><span class="mbri-chat mbr-iconfont mbr-iconfont-btn" style="color: rgb(0, 0, 0);"></span>
                        <font size="+1">Research</font></a></li>
                <li class="nav-item"><a class="nav-link link text-black display-4" href="Journal.html"><span class="mbrib-edit mbr-iconfont mbr-iconfont-btn" style="color: rgb(0, 0, 0);"></span>
                        <font size="+1">Publications</font></a>
                </li>
                <li class="nav-item"><a class="nav-link link text-black display-4" href="OurGroup.html"><span class="mbrib-users mbr-iconfont mbr-iconfont-btn" style="color: rgb(0, 0, 0);"></span>
                    <font size="+1">Members</font><br></a>
                </li><li class="nav-item"><a class="nav-link link text-black display-4" href="News.html"><span class="mbrib-preview mbr-iconfont mbr-iconfont-btn" style="color: rgb(0, 0, 0);"></span>
                        <font size="+1">News</font></a></li><li class="nav-item"><a class="nav-link link text-black display-4" href="OpenPositions.html"><span class="mbrib-search mbr-iconfont mbr-iconfont-btn" style="color: rgb(0, 0, 0);"></span>
                        <font size="+1">Open Positions</font></a></li><li class="nav-item"><a class="nav-link link text-black display-4" href="ContactUs.html"><span class="mbrib-letter mbr-iconfont mbr-iconfont-btn" style="color: rgb(0, 0, 0);"></span>
                        <font size="+1">Contact Us</font></a></li></ul>
            
        </div>
    </nav>
</section>

<section class="header1 cid-rcO6d1dMDc mbr-parallax-background" id="header1-3u">

    

    

    <div class="container">
        <div class="row justify-content-md-center">
            <div class="mbr-white col-md-10">
                <h1 class="mbr-section-title align-center mbr-bold pb-3 mbr-fonts-style display-1">
                    Research Topic</h1>
                
                
                
            </div>
        </div>
    </div>

</section>

<section class="mbr-section content4 cid-rcOnR0BAWJ" id="content4-4y">

    

    <div class="container">
        <div class="media-container-row">
            <div class="title col-12 col-md-8">
                <h2 class="align-center pb-3 mbr-fonts-style display-2">Heterogeneous Chiplet-Based Architectures</h2>
                <h3 class="mbr-section-subtitle align-center mbr-light mbr-fonts-style display-5">Current Researchers: Dr. Hao Zheng, Yuan Li, and Jasmine Pillarisetti;</h3>
                
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content1 cid-rcOnSaeB6J" id="content1-50">
    
     

    <div class="container">
        <div class="media-container-row">
            <div class="mbr-text col-12 col-md-8 mbr-fonts-style display-7"><div>In the dark silicon era, only a fraction of transistors on a chip can be switched on simultaneously, due to the constrained power budget. To improve energy-efficiency, general-purpose cores are augmented with multiple types of accelerators. The general-purpose cores and accelerators can be integrated on a single chip or in an emerging chiplet-based system. The integration of heterogeneous cores on a chip or in a chiplet-based system is putting stringent demands on the communication fabric, as the heterogeneous cores with different microarchitectures and programming models usually have distinct traffic patterns and sensitivities to network latency and bandwidth.</div><div><br></div><div>In this research project, we address the interconnection design challenges by fully exploring the traffic patterns of diverse types of cores and then designing the interconnection network which can be configured to adapt to specific traffic patterns. We are especially interested in utilizing the wiring resource in silicon interposer in chiplet systems to design the interconnection network.</div></div>
        </div>
    </div>
</section>

<section class="mbr-section article content12 cid-tldejU7oBe" id="content6-ei">
     

    <div class="container">
        <div class="media-container-row">
            <div class="mbr-text counter-container col-12 col-md-8 mbr-fonts-style pt-5">
                <div class="mb-5">
                    <h4 class="counter">01.</h4>
                    <h3 class="mb-3 mbr-fonts-style display-5">Y. Li, A. Louri, and A. Karanth, "SPACX: Silicon Photonics-based Scalable Chiplet Accelerator for DNN Inference", in <em>Proceedings of the IEEE International Symposium on High-Performance Computer Architecture (HPCA)</em>, Virtual Conference, April 2-6, 2022.</h3>
                    <p class="mbr-fonts-style display-7">In pursuit of higher inference accuracy, deep neural network (DNN) models have significantly increased in complexity and size. To overcome the consequent computational challenges, scalable chiplet-based accelerators have been proposed. However, data communication using metallic-based interconnects in these chiplet-based DNN accelerators is becoming a primary obstacle to performance, energy efficiency, and scalability. The photonic interconnects can provide adequate data communication support due to some superior properties like low latency, high bandwidth and energy efficiency, and ease of broadcast communication. In this project, we propose SPACX: a Silicon Photonics-based Chiplet Accelerator for DNN inference applications. Specifically, SPACX includes a photonic network design that enables seamless single-chiplet and cross-chiplet broadcast communications, and a tailored dataflow that promotes data broadcast and maximizes parallelism. Furthermore, we explore the broadcast granularities of the photonic network and implications on system performance and energy efficiency. A flexible bandwidth allocation scheme is also proposed to dynamically adjust communication bandwidths for different types of data. Simulation results using several DNN models show that SPACX can achieve 78 percent and 75 percent reduction in execution time and energy, respectively, as compared to other state-of-the-art chiplet-based DNN accelerators.<br></p>
                </div>
              
            </div>
        </div>
    </div>
</section>

<section class="cid-tldekoEoJC" id="image2-ej">

    

    <figure class="mbr-figure container">
        <div class="image-block" style="width: 64%;">
            <img src="assets/images/spacx-1348x632.png" alt="" title="">
            
        </div>
    </figure>
</section>

<section class="mbr-section article content12 cid-rdX1X9UmGR" id="content6-9d">
     

    <div class="container">
        <div class="media-container-row">
            <div class="mbr-text counter-container col-12 col-md-8 mbr-fonts-style pt-5">
                <div class="mb-5">
                    <h4 class="counter">02.</h4>
                    <h3 class="mb-3 mbr-fonts-style display-5">Y. Li, A. Louri, and A. Karanth, "Scaling Deep-Learning Inference with Chiplet-based Architecture and Photonic Interconnects", in <em>Proceedings of the Design Automation Conference</em>, San Francisco, CA, December 5-9, 2021.</h3>
                    <p class="mbr-fonts-style display-7">Chiplet-based architectures have been proposed to scale computing systems for deep neural networks (DNNs). Prior work has shown that for the chiplet-based DNN accelerators, the electrical network connecting the chiplets poses a major challenge to system performance, energy consumption, and scalability. Some emerging interconnect technologies such as silicon photonics can potentially overcome the challenges facing electrical interconnects as photonic interconnects provide high bandwidth density, superior energy efficiency, and ease of implementing broadcast and multicast operations that are prevalent in DNN inference. In this project, we propose a chiplet-based architecture named SPRINT for DNN inference. SPRINT uses a global buffer to simplify the data transmission between storage and computation, and includes two novel designs: (1) a reconfigurable photonic network that can support diverse communications in DN inference with minimal implementation cost, and (2) a customized dataflow that exploits the ease of broadcast and multicast feature of photonic interconnects to support highly parallel DNN computations. Simulation studies using ResNet-50 DNN&nbsp; model show&nbsp; that SPRNT achieves 46 percent and 61 percent execution time and energy consumption reduction, respectively, as compared to other state-of-the-art chiplet-based architectures with electrical or photonic interconnects.<br></p>
                </div>
              
            </div>
        </div>
    </div>
</section>

<section class="cid-thfpqFyvn6" id="image2-ci">

    

    <figure class="mbr-figure container">
        <div class="image-block" style="width: 79%;">
            <img src="assets/images/dac-1284x359.png" alt="" title="">
            
        </div>
    </figure>
</section>

<section class="mbr-section article content12 cid-thfpj5Edu7" id="content6-cg">
     

    <div class="container">
        <div class="media-container-row">
            <div class="mbr-text counter-container col-12 col-md-8 mbr-fonts-style pt-5">
                <div class="mb-5">
                    <h4 class="counter">03.</h4>
                    <h3 class="mb-3 mbr-fonts-style display-5">H. Zheng, K. Wang, and A. Louri, "Adapt-NoC: A Flexible Network-on-Chip Design for Heterogeneous Manycore Architectures", in <em>Proceedings of the IEEE International Symposium on High-Performance Computer Architecture (HPCA)</em>, Virtual Conference, February 27 - March 3, 2021.</h3>
                    <p class="mbr-fonts-style display-7">The increased computational capability in heterogeneous manycore architectures facilitates the concurrent execution of many applications. This requires, among other things, a flexible, high-performance, and energy-efficient communication fabric capable of handling a variety of traffic patterns needed for running multiple applications at the same time. Such stringent requirements are posing a major challenge for current Network-on-Chips (NoCs) design. In this project, we propose Adapt-NoC, a flexible NoC architecture, along with a reinforcement learning (RL)-based control policy, that can provide efficient communication support for concurrent application execution. Adapt-NoC can dynamically allocate several disjoint regions of the NoC, called subNoCs, with different sizes and locations for the concurrently running applications. Each of the dynamically-allocated subNoCs is capable of adapting to a given topology such as a mesh, cmesh, torus, or tree thus tailoring the topology to satisfy application's needs in terms of performance and power consumption. Moreover, we explore the use of RL to design an efficient control policy which optimizes the subNoC topology selection for a given application. As such, Adapt-NoC can not only provide several topology choices for concurrently running applications, but can also optimize the selection of the most suitable topology for a given application with the aim of improving performance and energy efficiency. We evaluate Adapt-NoC using both GPU and CPU benchmark suites. Simulation results show that the proposed Adapt-NoC can achieve up to 34 percent latency reduction, 10 percent overall execution time reduction and 53 percent NoC energy-efficiency improvement when compared to prior work.<br></p>
                </div>
              
            </div>
        </div>
    </div>
</section>

<section class="cid-thfpr41Xe3" id="image2-cj">

    

    <figure class="mbr-figure container">
        <div class="image-block" style="width: 81%;">
            <img src="assets/images/adaptnoc-1987x514.png" alt="" title="">
            
        </div>
    </figure>
</section>

<section class="mbr-section article content12 cid-thfppyhcah" id="content6-ch">
     

    <div class="container">
        <div class="media-container-row">
            <div class="mbr-text counter-container col-12 col-md-8 mbr-fonts-style pt-5">
                <div class="mb-5">
                    <h4 class="counter">04.</h4>
                    <h3 class="mb-3 mbr-fonts-style display-5">H. Zheng, K. Wang, and A. Louri, “A Versatile and Flexible Chiplet-based System Design for Heterogeneous Manycore Architectures”, in <em>Proceedings of Design Automation Conference</em>, Virtual Conference, July 20-24, 2020.</h3>
                    <p class="mbr-fonts-style display-7">Heterogeneous manycore architectures are deployed to simultaneously run multiple and diverse applications. This requires various computing capabilities (CPUs, GPUs, and accelerators), and an efficient network-on-chip (NoC) architecture to concurrently handle diverse application communication behavior. However, supporting the concurrent communication requirements of diverse applications is challenging due to the dynamic application mapping, the complexity of handling distinct communication patterns and limited on-chip resources. In this project, we propose Adapt-NoC, a versatile and flexible NoC architecture for chiplet-based manycore architectures, consisting of adaptable routers and links. Adapt-NoC can dynamically allocate disjoint regions of the NoC, called subNoCs, for concurrently-running applications, each of which can be optimized for different communication behavior. The adaptable routers and links are capable of providing various subNoC topologies, satisfying different latency and bandwidth requirements of various traffic patterns (e.g. all-to-all, one-to-many). Full system simulation shows that AdaptNoC can achieve 31 percent latency reduction, 24 percent energy saving and 10 percent execution time reduction on average, when compared to prior designs.<br></p>
                </div>
              
            </div>
        </div>
    </div>
</section>

<section class="cid-thfprpCUh8" id="image2-ck">

    

    <figure class="mbr-figure container">
        <div class="image-block" style="width: 79%;">
            <img src="assets/images/versatile-1815x478.png" alt="" title="">
            
        </div>
    </figure>
</section>

<section class="cid-rdPq2IPGYy" id="footer1-8n">

    

    

    <div class="container">
        <div class="media-container-row content text-white">
            <div class="col-12 col-md-3">
                <div class="media-wrap">
                    <a href="#top">
                        <img src="assets/images/screen-shot-2018-12-31-at-12.35.34-310x302.png" alt="" title="">
                    </a>
                </div>
            </div>
            <div class="col-12 col-md-5 mbr-fonts-style display-7">
                <h5 class="pb-3"><strong>HPCAT Lab<br>High Performance Computing Architectures &amp; Technologies&nbsp;Lab</strong><br></h5>
                <p class="mbr-text"><strong>Department of Electrical and Computer Enginnering </strong><br><strong>School of Engineering and Applied Science<br>The George Washington University </strong><br><br>800 22nd Street NW<br>Washington, DC 20052<br>United States of America&nbsp;</p>
            </div>
            <div class="col-12 col-md-6 mbr-fonts-style display-7">
                <h5 class="pb-3"><strong>
                    Contact</strong></h5>
                <p class="mbr-text"><strong>Ahmed Louri, IEEE Fellow</strong><br>David and Marilyn Karlgaard Endowed Chair Professor of ECE<br>Director, &nbsp;HPCAT Lab&nbsp;<br><br><br>Email: louri@gwu.edu &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;<br>Phone: +1 (202) 994 8241<br></p>
            </div>
        </div>
        <div class="footer-lower">
            <div class="media-container-row">
                <div class="col-sm-12">
                    <hr>
                </div>
            </div>
            <div class="media-container-row mbr-white">
                <div class="col-sm-6 copyright">
                    <p class="mbr-text mbr-fonts-style display-7">
                        © Copyright 2019 HPCAT - All Rights Reserved
                    </p>
                </div>
                <div class="col-md-6">
                    <div class="social-list align-right">
                        <div class="soc-item">
                            <a href="https://twitter.com/HpcatLab" target="_blank">
                                <span class="mbr-iconfont mbr-iconfont-social socicon-twitter socicon" style="color: rgb(0, 0, 0); fill: rgb(0, 0, 0);"></span>
                            </a>
                        </div>
                        <div class="soc-item">
                            <a href="sorry.html">
                                <span class="mbr-iconfont mbr-iconfont-social socicon-facebook socicon" style="color: rgb(0, 0, 0); fill: rgb(0, 0, 0);"></span>
                            </a>
                        </div>
                        <div class="soc-item">
                            <a href="sorry.html">
                                <span class="mbr-iconfont mbr-iconfont-social socicon-youtube socicon" style="color: rgb(0, 0, 0); fill: rgb(0, 0, 0);"></span>
                            </a>
                        </div>
                        <div class="soc-item">
                            <a href="sorry.html">
                                <span class="mbr-iconfont mbr-iconfont-social socicon-instagram socicon" style="color: rgb(0, 0, 0); fill: rgb(0, 0, 0);"></span>
                            </a>
                        </div>
                        <div class="soc-item">
                            <a href="sorry.html">
                                <span class="mbr-iconfont mbr-iconfont-social socicon-googleplus socicon" style="color: rgb(0, 0, 0); fill: rgb(0, 0, 0);"></span>
                            </a>
                        </div>
                        <div class="soc-item">
                            <a href="sorry.html">
                                <span class="mbr-iconfont mbr-iconfont-social socicon-wechat socicon" style="color: rgb(0, 0, 0); fill: rgb(0, 0, 0);"></span>
                            </a>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content12 cid-tlcDbSFlCT" id="content6-di">
     

    <div class="container">
        <div class="media-container-row">
            <div class="mbr-text counter-container col-12 col-md-8 mbr-fonts-style pt-5">
                <div class="mb-5">
                    <h4 class="counter">01.</h4>
                    <h3 class="mb-3 mbr-fonts-style display-5">Y. Li, A. Louri, and A. Karanth, "Scaling Deep-Learning Inference with Chiplet-based Architecture and Photonic Interconnects", in <em>Proceedings of the Design Automation Conference</em>, San Francisco, CA, December 5-9, 2021.</h3>
                    <p class="mbr-fonts-style display-7">Chiplet-based architectures have been proposed to scale computing systems for deep neural networks (DNNs). Prior work has shown that for the chiplet-based DNN accelerators, the electrical network connecting the chiplets poses a major challenge to system performance, energy consumption, and scalability. Some emerging interconnect technologies such as silicon photonics can potentially overcome the challenges facing electrical interconnects as photonic interconnects provide high bandwidth density, superior energy efficiency, and ease of implementing broadcast and multicast operations that are prevalent in DNN inference. In this project, we propose a chiplet-based architecture named SPRINT for DNN inference. SPRINT uses a global buffer to simplify the data transmission between storage and computation, and includes two novel designs: (1) a reconfigurable photonic network that can support diverse communications in DN inference with minimal implementation cost, and (2) a customized dataflow that exploits the ease of broadcast and multicast feature of photonic interconnects to support highly parallel DNN computations. Simulation studies using ResNet-50 DNN&nbsp; model show&nbsp; that SPRNT achieves 46 percent and 61 percent execution time and energy consumption reduction, respectively, as compared to other state-of-the-art chiplet-based architectures with electrical or photonic interconnects.<br></p>
                </div>
              
            </div>
        </div>
    </div>
</section>

<section class="mbr-section article content12 cid-tlcDftNpDK" id="content6-dj">
     

    <div class="container">
        <div class="media-container-row">
            <div class="mbr-text counter-container col-12 col-md-8 mbr-fonts-style pt-5">
                <div class="mb-5">
                    <h4 class="counter">01.</h4>
                    <h3 class="mb-3 mbr-fonts-style display-5">Y. Li, A. Louri, and A. Karanth, "Scaling Deep-Learning Inference with Chiplet-based Architecture and Photonic Interconnects", in <em>Proceedings of the Design Automation Conference</em>, San Francisco, CA, December 5-9, 2021.</h3>
                    <p class="mbr-fonts-style display-7">Chiplet-based architectures have been proposed to scale computing systems for deep neural networks (DNNs). Prior work has shown that for the chiplet-based DNN accelerators, the electrical network connecting the chiplets poses a major challenge to system performance, energy consumption, and scalability. Some emerging interconnect technologies such as silicon photonics can potentially overcome the challenges facing electrical interconnects as photonic interconnects provide high bandwidth density, superior energy efficiency, and ease of implementing broadcast and multicast operations that are prevalent in DNN inference. In this project, we propose a chiplet-based architecture named SPRINT for DNN inference. SPRINT uses a global buffer to simplify the data transmission between storage and computation, and includes two novel designs: (1) a reconfigurable photonic network that can support diverse communications in DN inference with minimal implementation cost, and (2) a customized dataflow that exploits the ease of broadcast and multicast feature of photonic interconnects to support highly parallel DNN computations. Simulation studies using ResNet-50 DNN&nbsp; model show&nbsp; that SPRNT achieves 46 percent and 61 percent execution time and energy consumption reduction, respectively, as compared to other state-of-the-art chiplet-based architectures with electrical or photonic interconnects.<br></p>
                </div>
              
            </div>
        </div>
    </div>
</section>


<script src="assets/web/assets/jquery/jquery.min.js"></script>
  <script src="assets/popper/popper.min.js"></script>
  <script src="assets/bootstrap/js/bootstrap.min.js"></script>
  <script src="assets/tether/tether.min.js"></script>
  <script src="assets/smoothscroll/smooth-scroll.js"></script>
  <script src="assets/viewportchecker/jquery.viewportchecker.js"></script>
  <script src="assets/parallax/jarallax.min.js"></script>
  <script src="assets/dropdown/js/nav-dropdown.js"></script>
  <script src="assets/dropdown/js/navbar-dropdown.js"></script>
  <script src="assets/touchswipe/jquery.touch-swipe.min.js"></script>
  <script src="assets/theme/js/script.js"></script>
  
  
  
 <div id="scrollToTop" class="scrollToTop mbr-arrow-up"><a style="text-align: center;"><i class="mbr-arrow-up-icon mbr-arrow-up-icon-cm cm-icon cm-icon-smallarrow-up"></i></a></div>
    <input name="animation" type="hidden">
  </body>
</html>